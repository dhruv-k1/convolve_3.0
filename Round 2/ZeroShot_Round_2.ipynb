{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ___________                     __________                   _________.__            __    #\n",
    "# \\__    ___/___ _____    _____   \\____    /___________  ____ /   _____/|  |__   _____/  |_  #\n",
    "#   |    |_/ __ \\\\__  \\  /     \\    /     // __ \\_  __ \\/  _ \\\\_____  \\ |  |  \\ /  _ \\   __\\ #\n",
    "#   |    |\\  ___/ / __ \\|  Y Y  \\  /     /\\  ___/|  | \\(  <_> )        \\|   Y  (  <_> )  |   #\n",
    "#   |____| \\___  >____  /__|_|  / /_______ \\___  >__|   \\____/_______  /|___|  /\\____/|__|   #\n",
    "#              \\/     \\/      \\/          \\/   \\/                    \\/      \\/              #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\tData Preparation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Demographics Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_30628\\588122452.py:1: DtypeWarning: Columns (7,12,13,15,16,17,18,19,29,37,45,46,47,56,58,66,69,71,74,228) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_cdna = pd.read_csv(\"train_cdna_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "train_cdna = pd.read_csv(\"train_cdna_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cdna = train_cdna.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1285402 entries, 0 to 1285401\n",
      "Columns: 278 entries, CUSTOMER_CODE to batch_date\n",
      "dtypes: bool(9), float64(156), int64(35), object(78)\n",
      "memory usage: 2.6+ GB\n"
     ]
    }
   ],
   "source": [
    "train_cdna.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1\t Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped due to >40% missing values:\n",
      "['v8', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v28', 'v32', 'v38', 'v42', 'v44', 'v46', 'v47', 'v48', 'v55', 'v57', 'v58', 'v59', 'v61', 'v62', 'v63', 'v64', 'v65', 'v66', 'v67', 'v68', 'v69', 'v70', 'v71', 'v72', 'v74', 'v75', 'v77', 'v79', 'v84', 'v85', 'v99', 'v103', 'v107', 'v108', 'v109', 'v110', 'v111', 'v112', 'v113', 'v114', 'v115', 'v116', 'v117', 'v118', 'v119', 'v120', 'v121', 'v122', 'v123', 'v124', 'v125', 'v126', 'v127', 'v128', 'v129', 'v130', 'v131', 'v132', 'v133', 'v134', 'v135', 'v136', 'v137', 'v138', 'v139', 'v140', 'v141', 'v142', 'v143', 'v144', 'v145', 'v146', 'v147', 'v148', 'v155', 'v156', 'v157', 'v158', 'v159', 'v160', 'v161', 'v162', 'v163', 'v164', 'v165', 'v166', 'v167', 'v168', 'v169', 'v170', 'v171', 'v172', 'v173', 'v174', 'v175', 'v176', 'v177', 'v178', 'v179', 'v180', 'v181', 'v182', 'v183', 'v184', 'v185', 'v186', 'v187', 'v188', 'v189', 'v190', 'v191', 'v192', 'v193', 'v194', 'v195', 'v196', 'v197', 'v198', 'v199', 'v200', 'v201', 'v202', 'v203', 'v204', 'v205', 'v206', 'v207', 'v208', 'v209', 'v210', 'v211', 'v212', 'v213', 'v215', 'v216', 'v217', 'v218', 'v219', 'v220', 'v222', 'v223', 'v228', 'v231', 'v232', 'v233', 'v234', 'v235', 'v236', 'v237', 'v238', 'v239', 'v240', 'v241', 'v243', 'v244', 'v252', 'v253', 'v254', 'v255', 'v256', 'v257', 'v258']\n",
      "Number of columns dropped: 172\n",
      "\n",
      "Shape of original train_cdna: (1285402, 278)\n",
      "\n",
      "Shape of original train_cdna after using inplace=True: (1285402, 106)\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of missing values per column\n",
    "missing_percentages = (train_cdna.isna().sum() / len(train_cdna)) * 100\n",
    "\n",
    "# Identify columns to drop (more than 40% missing)\n",
    "columns_to_drop = missing_percentages[missing_percentages > 40].index\n",
    "\n",
    "\n",
    "# Print information about dropped columns (optional)\n",
    "if not columns_to_drop.empty:\n",
    "    print(\"Columns dropped due to >40% missing values:\")\n",
    "    print(columns_to_drop.tolist())\n",
    "    print(f\"Number of columns dropped: {len(columns_to_drop)}\")\n",
    "else:\n",
    "    print(\"No columns had more than 40% missing values.\")\n",
    "\n",
    "print(\"\\nShape of original train_cdna:\", train_cdna.shape)\n",
    "\n",
    "#Demonstration using inplace=True\n",
    "train_cdna.drop(columns=columns_to_drop, inplace=True)\n",
    "print(\"\\nShape of original train_cdna after using inplace=True:\", train_cdna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 106 columns.\n",
      "There are 59 columns that have missing values.\n"
     ]
    }
   ],
   "source": [
    "mis_val = train_cdna.isnull().sum()\n",
    "\n",
    "    # Percentage of missing values\n",
    "mis_val_percent = 100 * train_cdna.isnull().sum() / len(train_cdna)\n",
    "\n",
    "    # Make a table with the results\n",
    "mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "mis_val_table_ren_columns = mis_val_table.rename(\n",
    "columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "\n",
    "    # Sort the table by percentage of missing descending\n",
    "mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    # Print some summary information\n",
    "print (\"Your selected dataframe has \" + str(train_cdna.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2\t Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['CUSTOMER_CODE', 'v2', 'v6', 'v9','v27','v29','v36','v54','v80','v81','v100','v101','v102','batch_date']\n",
    "train_demo = train_cdna[columns_to_extract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values per column (descending order):\n",
      "v102: 18.49%\n",
      "v29: 18.23%\n",
      "v27: 4.69%\n",
      "v80: 3.52%\n",
      "v2: 3.52%\n",
      "v54: 3.52%\n",
      "v101: 2.67%\n",
      "v9: 1.64%\n",
      "v6: 0.30%\n",
      "v81: 0.01%\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(train_demo)\n",
    "missing_percentage = (train_demo.isnull().sum() / total_rows) * 100\n",
    "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False) # Only print if there are missing values\n",
    "if missing_percentage.empty:\n",
    "    print(\"No missing values found in the DataFrame.\")\n",
    "else:\n",
    "    print(\"Percentage of missing values per column (descending order):\")\n",
    "    for column, percentage in missing_percentage.items():\n",
    "        print(f\"{column}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_counts = train_demo['v102'].value_counts() / 1000\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
    "plt.bar(value_counts.index, value_counts.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Values in v100\")\n",
    "plt.ylabel(\"Frequency (in thousands)\")\n",
    "plt.title(\"Frequency of Values in v100\")\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for i, v in enumerate(value_counts):\n",
    "    plt.text(i, v, str(round(v, 2)), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_30628\\1042971726.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_demo.fillna(train_demo.mode().iloc[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_demo.fillna(train_demo.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(train_demo)\n",
    "missing_percentage = (train_demo.isnull().sum() / total_rows) * 100\n",
    "missing_percentage = missing_percentage[missing_percentage > 0].sort_values(ascending=False) # Only print if there are missing values\n",
    "if missing_percentage.empty:\n",
    "    print(\"No missing values found in the DataFrame.\")\n",
    "else:\n",
    "    print(\"Percentage of missing values per column (descending order):\")\n",
    "    for column, percentage in missing_percentage.items():\n",
    "        print(f\"{column}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['v6', 'v9','v80']\n",
    "train_demo = train_demo.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unique values in column 'v2': ['50-54' '35-39' '20-24' '30-34' '25-29' '40-44' '60-64' '45-49' '55-59'\n",
      " '65-69' '15-19' '70-74' '75-79' '0-4' '85-89' '80-84' '10-14' '5-9'\n",
      " '90-94' '95-99' '100-104' '125-129']\n",
      "\n",
      " Unique values in column 'v27': ['MARRIED' 'Married' 'Unmarried' 'UNMARRIED' 'S' 'M' 'OTHER' 'Widow'\n",
      " 'SINGLE' 'WIDOW' 'Single']\n",
      "\n",
      " Unique values in column 'v29': ['SALARIED' 'Self Employed Business' 'Salaried' 'Homemaker'\n",
      " 'SELF EMPLOYED' 'Salaried-Private' 'OTHER' 'Student'\n",
      " 'Selp employed profesional' 'Salarid-Public' 'Retired' 'Salarid-Govt'\n",
      " 'OTHERSSTUDENT' 'Self Employed' 'Self Employed Professional-Doctor'\n",
      " 'Farmer' 'CORPORATE' 'Unemployed' 'Self Employed Professional-CA'\n",
      " 'NA - Minor' 'NORMAL' 'INDIVIDUAL SELF EMPLOYED' 'INDIVIDUAL SALARIED'\n",
      " 'SALARIEDPRIVATESECTOR' 'OTHERSNOTCATEGORIZED'\n",
      " 'Self employed professional' 'STUDENT' 'Non earning individuals'\n",
      " 'Self Employed Professional-Consultant'\n",
      " 'Self Employed Professional-Architect' 'Professional'\n",
      " 'Self Employed Professional-Entertainment' 'SELFEMPLOYEDBUSINESS'\n",
      " 'AlliedAgri-Dairy' 'Allied Agri-Dairy'\n",
      " 'SELF EMPLOYED PRIORITY SECTOR LENDING'\n",
      " 'Self Employed Professional-Lawyer' 'PENSIONER'\n",
      " 'SELFEMPLOYEDPROFESSIONAL' 'Retd. Pensioner' 'AlliedAgri-Goat'\n",
      " 'SALARIEDPUBLICSECTOR' 'GROUP COMPANY EMPLOYEE' 'PROFESSIONAL'\n",
      " 'HOUSE WIFE' 'Service-Trader' 'SelfEmployed  Non-Agri - Service Provider'\n",
      " 'SELF EMPLOYED BUSINESS' 'SALARIEDGOVERNMENTSECTOR' 'House Wife'\n",
      " 'NON-INDIVIDUAL' 'OTHERS' 'Labour-OtherLabour' 'Salaried-Public'\n",
      " 'Salaried-Govt' 'Self Employed Professional-Beautician'\n",
      " 'Agri-Marginal Farmer up to 2.5 Acre' 'AlliedAgri-Fishery'\n",
      " 'INDIVIDUAL OTHERS' 'Company labour'\n",
      " 'Agri-Marginal Farmer (up to 2.5 Acre)'\n",
      " 'Self Employed Professional-Alternate Medical Pract'\n",
      " 'Salaried  Non-Agri - Private Employee' 'Self employed Non Professional'\n",
      " 'Cloth Sales' 'OTHERSHOUSEWIFE' 'Agri-Small Farmer 2.5-5 Acre'\n",
      " 'AlliedAgri-Others' 'Self employed Specified (Shroff, Money Lender, Sto'\n",
      " 'HOMEMAKER' 'Salaried-Others' 'Coconut Sales'\n",
      " 'SELF EMPLOYED - NON PROFESSIONAL' 'TW' 'Foodbeverage-DhabaOrTea Stall'\n",
      " 'Tailor' 'Labour-Other  Labour' 'Foodbeverage-FruitOrVegetableVendor'\n",
      " 'Labour-AgriLabour' 'Landless Labour'\n",
      " 'SELF EMPLOYED  NON PRIORITY SECTOR LENDING' 'SELFEMP'\n",
      " 'Agri-Small Farmer (2.5-5 Acre)' 'AlliedAgri-Poultry'\n",
      " 'SelfEmployed  Agri - DairyAnimal Husbandry' 'AlliedAgri-Sheep' 'Hotel'\n",
      " 'Salaried - Govt' 'EMP' 'Service-TransportOperator' 'Daily Labour' 'CD'\n",
      " 'TVS' 'Politician' 'Service-Tailor' 'RETIRED' 'FARMER' 'EMPLOYEE'\n",
      " 'SD/MBO']\n",
      "\n",
      " Unique values in column 'v36': ['MDM' 'MDM_CORP' 'FINNONE' 'CUSTOMER']\n",
      "\n",
      " Unique values in column 'v54': ['MALE' 'Male' 'Female' 'FEMALE' 'M' 'F' 'C' 'THIRD GENDER' 'OTHERS' 'U'\n",
      " 'O']\n",
      "\n",
      " Unique values in column 'v81': ['N' 'Y']\n",
      "\n",
      " Unique values in column 'v100': [1 3 2 4]\n",
      "\n",
      " Unique values in column 'v101': ['Tier 1' 'Tier 5' 'Tier 6' 'Tier 2' 'Tier 7' 'Tier 8' 'Tier 3' 'Tier 4'\n",
      " 'Rural']\n",
      "\n",
      " Unique values in column 'v102': ['Salaried' 'Self_Employed' 'Homemaker' 'Other' 'Student' 'Retired'\n",
      " 'Unemployed' 'Minor']\n"
     ]
    }
   ],
   "source": [
    "for col_name in train_demo.columns[1:-1]:  # Iterate from the second to the second-to-last column\n",
    "        unique_values = train_demo[col_name].unique()\n",
    "        print(f\"\\n Unique values in column '{col_name}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning v54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v54\n",
      "Male            39.725860\n",
      "MALE            33.549816\n",
      "Female          10.636672\n",
      "M                9.318097\n",
      "FEMALE           5.733693\n",
      "F                1.016491\n",
      "C                0.009336\n",
      "THIRD GENDER     0.005913\n",
      "OTHERS           0.002256\n",
      "U                0.001400\n",
      "O                0.000467\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage counts\n",
    "percent_counts = train_demo['v54'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v54\n",
      "male            82.593772\n",
      "female          17.386856\n",
      "c                0.009336\n",
      "third gender     0.005913\n",
      "others           0.002256\n",
      "u                0.001400\n",
      "o                0.000467\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert all values to lowercase\n",
    "train_demo['v54'] = train_demo['v54'].str.lower()\n",
    "\n",
    "# Replace values starting with \"salary\" with \"salaried\"\n",
    "train_demo['v54'] = train_demo['v54'].replace(r'^m.*', 'male', regex=True)\n",
    "\n",
    "# Replace values starting with \"sel..\" with \"self employed\"\n",
    "train_demo['v54'] = train_demo['v54'].replace(r'^f.*', 'female', regex=True)\n",
    "\n",
    "# Merge values with the same names (already handled by string operations)\n",
    "# Optional: Re-calculate value counts to verify\n",
    "pct_count = train_demo['v54'].value_counts(normalize=True)*100\n",
    "\n",
    "# Print the updated value counts\n",
    "print(pct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v54\n",
      "male      82.593772\n",
      "female    17.386856\n",
      "other      0.019371\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "keep_values = ['male', 'female']\n",
    "\n",
    "# Replace all other values with 'other'\n",
    "train_demo['v54'] = train_demo['v54'].apply(lambda x: x if x in keep_values else 'other')\n",
    "\n",
    "# Verify the changes by checking the updated value counts\n",
    "pct_counts = train_demo['v54'].value_counts(normalize=True)*100\n",
    "print(pct_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning v27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v27\n",
      "Unmarried    36.515892\n",
      "MARRIED      28.792627\n",
      "Married      15.018803\n",
      "UNMARRIED    11.365316\n",
      "M             7.247538\n",
      "S             1.057568\n",
      "OTHER         0.000934\n",
      "SINGLE        0.000622\n",
      "Single        0.000389\n",
      "WIDOW         0.000233\n",
      "Widow         0.000078\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage counts\n",
    "percent_counts = train_demo['v27'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentages\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v27\n",
      "married      51.058968\n",
      "unmarried    47.881208\n",
      "single        1.058579\n",
      "other         0.000934\n",
      "widow         0.000311\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert all values to lowercase\n",
    "train_demo['v27'] = train_demo['v27'].str.lower()\n",
    "\n",
    "# Replace values starting with \"salary\" with \"salaried\"\n",
    "train_demo['v27'] = train_demo['v27'].replace(r'^m.*', 'married', regex=True)\n",
    "\n",
    "# Replace values starting with \"sel..\" with \"self employed\"\n",
    "train_demo['v27'] = train_demo['v27'].replace(r'^s.*', 'single', regex=True)\n",
    "\n",
    "# Merge values with the same names (already handled by string operations)\n",
    "# Optional: Re-calculate value counts to verify\n",
    "pct_count = train_demo['v27'].value_counts(normalize=True)*100\n",
    "\n",
    "# Print the updated value counts\n",
    "print(pct_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning v29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v29\n",
      "salaried                                 64.340494\n",
      "self employed                            23.975223\n",
      "homemaker                                 3.183518\n",
      "other                                     2.834522\n",
      "student                                   2.179240\n",
      "retired                                   1.293136\n",
      "farmer                                    0.934960\n",
      "professional                              0.294694\n",
      "na - minor                                0.269954\n",
      "normal                                    0.197526\n",
      "individual salaried                       0.165551\n",
      "unemployed                                0.090789\n",
      "corporate                                 0.057414\n",
      "individual self employed                  0.056325\n",
      "retd. pensioner                           0.030107\n",
      "house wife                                0.011825\n",
      "pensioner                                 0.010269\n",
      "others                                    0.010191\n",
      "group company employee                    0.008480\n",
      "non-individual                            0.007935\n",
      "service-trader                            0.005601\n",
      "othersstudent                             0.004201\n",
      "alliedagri-dairy                          0.003734\n",
      "othershousewife                           0.003267\n",
      "allied agri-dairy                         0.002412\n",
      "alliedagri-goat                           0.002334\n",
      "labour-otherlabour                        0.002334\n",
      "othersnotcategorized                      0.001867\n",
      "tailor                                    0.001867\n",
      "agri-marginal farmer (up to 2.5 acre)     0.001867\n",
      "individual others                         0.001867\n",
      "labour-agrilabour                         0.001400\n",
      "emp                                       0.001323\n",
      "agri-marginal farmer up to 2.5 acre       0.001011\n",
      "daily labour                              0.000934\n",
      "agri-small farmer (2.5-5 acre)            0.000934\n",
      "foodbeverage-fruitorvegetablevendor       0.000934\n",
      "alliedagri-sheep                          0.000934\n",
      "agri-small farmer 2.5-5 acre              0.000934\n",
      "politician                                0.000778\n",
      "non earning individuals                   0.000467\n",
      "cloth sales                               0.000467\n",
      "hotel                                     0.000467\n",
      "alliedagri-poultry                        0.000467\n",
      "tw                                        0.000467\n",
      "coconut sales                             0.000467\n",
      "alliedagri-others                         0.000467\n",
      "alliedagri-fishery                        0.000467\n",
      "company labour                            0.000467\n",
      "landless labour                           0.000467\n",
      "employee                                  0.000467\n",
      "sd/mbo                                    0.000467\n",
      "service-tailor                            0.000467\n",
      "service-transportoperator                 0.000467\n",
      "labour-other  labour                      0.000311\n",
      "foodbeverage-dhabaortea stall             0.000233\n",
      "tvs                                       0.000156\n",
      "cd                                        0.000078\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert all values to lowercase\n",
    "train_demo['v29'] = train_demo['v29'].str.lower()\n",
    "\n",
    "# Replace values starting with \"salary\" with \"salaried\"\n",
    "train_demo['v29'] = train_demo['v29'].replace(r'^sala.*', 'salaried', regex=True)\n",
    "\n",
    "# Replace values starting with \"sel..\" with \"self employed\"\n",
    "train_demo['v29'] = train_demo['v29'].replace(r'^sel.*', 'self employed', regex=True)\n",
    "\n",
    "# Merge values with the same names (already handled by string operations)\n",
    "# Optional: Re-calculate value counts to verify\n",
    "pct_count = train_demo['v29'].value_counts(normalize=True)*100\n",
    "\n",
    "# Print the updated value counts\n",
    "print(pct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v29\n",
      "salaried         64.340494\n",
      "self employed    23.975223\n",
      "other             4.937599\n",
      "homemaker         3.183518\n",
      "student           2.179240\n",
      "retired           1.293136\n",
      "unemployed        0.090789\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "keep_values = ['salaried', 'unemployed','self employed','homemaker','student','retired']\n",
    "\n",
    "# Replace all other values with 'other'\n",
    "train_demo['v29'] = train_demo['v29'].apply(lambda x: x if x in keep_values else 'other')\n",
    "\n",
    "# Verify the changes by checking the updated value counts\n",
    "pct_counts = train_demo['v29'].value_counts(normalize=True)*100\n",
    "print(pct_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unique values in column 'v2': ['50-54' '35-39' '20-24' '30-34' '25-29' '40-44' '60-64' '45-49' '55-59'\n",
      " '65-69' '15-19' '70-74' '75-79' '0-4' '85-89' '80-84' '10-14' '5-9'\n",
      " '90-94' '95-99' '100-104' '125-129']\n",
      "\n",
      " Unique values in column 'v27': ['married' 'unmarried' 'single' 'other' 'widow']\n",
      "\n",
      " Unique values in column 'v29': ['salaried' 'self employed' 'homemaker' 'other' 'student' 'retired'\n",
      " 'unemployed']\n",
      "\n",
      " Unique values in column 'v36': ['MDM' 'MDM_CORP' 'FINNONE' 'CUSTOMER']\n",
      "\n",
      " Unique values in column 'v54': ['male' 'female' 'other']\n",
      "\n",
      " Unique values in column 'v81': ['N' 'Y']\n",
      "\n",
      " Unique values in column 'v100': [1 3 2 4]\n",
      "\n",
      " Unique values in column 'v101': ['Tier 1' 'Tier 5' 'Tier 6' 'Tier 2' 'Tier 7' 'Tier 8' 'Tier 3' 'Tier 4'\n",
      " 'Rural']\n",
      "\n",
      " Unique values in column 'v102': ['Salaried' 'Self_Employed' 'Homemaker' 'Other' 'Student' 'Retired'\n",
      " 'Unemployed' 'Minor']\n"
     ]
    }
   ],
   "source": [
    "for col_name in train_demo.columns[1:-1]:  # Iterate from the second to the second-to-last column\n",
    "        unique_values = train_demo[col_name].unique()\n",
    "        print(f\"\\n Unique values in column '{col_name}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.3   One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_demo_encoded = pd.get_dummies(train_demo, columns=['v2', 'v27','v29', 'v36', 'v54', 'v81', 'v100', 'v101', 'v102'], prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_CODE</th>\n",
       "      <th>batch_date</th>\n",
       "      <th>v2_0-4</th>\n",
       "      <th>v2_10-14</th>\n",
       "      <th>v2_100-104</th>\n",
       "      <th>v2_125-129</th>\n",
       "      <th>v2_15-19</th>\n",
       "      <th>v2_20-24</th>\n",
       "      <th>v2_25-29</th>\n",
       "      <th>v2_30-34</th>\n",
       "      <th>...</th>\n",
       "      <th>v101_Tier 7</th>\n",
       "      <th>v101_Tier 8</th>\n",
       "      <th>v102_Homemaker</th>\n",
       "      <th>v102_Minor</th>\n",
       "      <th>v102_Other</th>\n",
       "      <th>v102_Retired</th>\n",
       "      <th>v102_Salaried</th>\n",
       "      <th>v102_Self_Employed</th>\n",
       "      <th>v102_Student</th>\n",
       "      <th>v102_Unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ab617a6a0a8582f4aaa1aeda38fd73377cb911e6096a98...</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e8e3227297409f3f33578400302825263cadc2ed0d1a0...</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b42f270aba756b64d7ae4e2409313097b0c91f7c2f2c7...</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06a4aae9b531a518260c7d0d88811cc202fd0d3e46d9ea...</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e4fa92b7a41dc019c9f40457e180e94ca60d0b5c7128e...</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       CUSTOMER_CODE  batch_date  v2_0-4  \\\n",
       "0  ab617a6a0a8582f4aaa1aeda38fd73377cb911e6096a98...  2024-09-27   False   \n",
       "1  6e8e3227297409f3f33578400302825263cadc2ed0d1a0...  2024-09-27   False   \n",
       "2  1b42f270aba756b64d7ae4e2409313097b0c91f7c2f2c7...  2024-09-27   False   \n",
       "3  06a4aae9b531a518260c7d0d88811cc202fd0d3e46d9ea...  2024-09-27   False   \n",
       "4  0e4fa92b7a41dc019c9f40457e180e94ca60d0b5c7128e...  2024-09-27   False   \n",
       "\n",
       "   v2_10-14  v2_100-104  v2_125-129  v2_15-19  v2_20-24  v2_25-29  v2_30-34  \\\n",
       "0     False       False       False     False     False     False     False   \n",
       "1     False       False       False     False     False     False     False   \n",
       "2     False       False       False     False      True     False     False   \n",
       "3     False       False       False     False      True     False     False   \n",
       "4     False       False       False     False     False     False      True   \n",
       "\n",
       "   ...  v101_Tier 7  v101_Tier 8  v102_Homemaker  v102_Minor  v102_Other  \\\n",
       "0  ...        False        False           False       False       False   \n",
       "1  ...        False        False           False       False       False   \n",
       "2  ...        False        False           False       False       False   \n",
       "3  ...        False        False           False       False       False   \n",
       "4  ...        False        False            True       False       False   \n",
       "\n",
       "   v102_Retired  v102_Salaried  v102_Self_Employed  v102_Student  \\\n",
       "0         False           True               False         False   \n",
       "1         False          False                True         False   \n",
       "2         False           True               False         False   \n",
       "3         False           True               False         False   \n",
       "4         False          False               False         False   \n",
       "\n",
       "   v102_Unemployed  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_demo_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_demo_encoded = train_demo_encoded * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1285402 entries, 0 to 1285401\n",
      "Data columns (total 66 columns):\n",
      " #   Column              Non-Null Count    Dtype \n",
      "---  ------              --------------    ----- \n",
      " 0   CUSTOMER_CODE       1285402 non-null  object\n",
      " 1   batch_date          1285402 non-null  object\n",
      " 2   v2_0-4              1285402 non-null  int64 \n",
      " 3   v2_10-14            1285402 non-null  int64 \n",
      " 4   v2_100-104          1285402 non-null  int64 \n",
      " 5   v2_125-129          1285402 non-null  int64 \n",
      " 6   v2_15-19            1285402 non-null  int64 \n",
      " 7   v2_20-24            1285402 non-null  int64 \n",
      " 8   v2_25-29            1285402 non-null  int64 \n",
      " 9   v2_30-34            1285402 non-null  int64 \n",
      " 10  v2_35-39            1285402 non-null  int64 \n",
      " 11  v2_40-44            1285402 non-null  int64 \n",
      " 12  v2_45-49            1285402 non-null  int64 \n",
      " 13  v2_5-9              1285402 non-null  int64 \n",
      " 14  v2_50-54            1285402 non-null  int64 \n",
      " 15  v2_55-59            1285402 non-null  int64 \n",
      " 16  v2_60-64            1285402 non-null  int64 \n",
      " 17  v2_65-69            1285402 non-null  int64 \n",
      " 18  v2_70-74            1285402 non-null  int64 \n",
      " 19  v2_75-79            1285402 non-null  int64 \n",
      " 20  v2_80-84            1285402 non-null  int64 \n",
      " 21  v2_85-89            1285402 non-null  int64 \n",
      " 22  v2_90-94            1285402 non-null  int64 \n",
      " 23  v2_95-99            1285402 non-null  int64 \n",
      " 24  v27_married         1285402 non-null  int64 \n",
      " 25  v27_other           1285402 non-null  int64 \n",
      " 26  v27_single          1285402 non-null  int64 \n",
      " 27  v27_unmarried       1285402 non-null  int64 \n",
      " 28  v27_widow           1285402 non-null  int64 \n",
      " 29  v29_homemaker       1285402 non-null  int64 \n",
      " 30  v29_other           1285402 non-null  int64 \n",
      " 31  v29_retired         1285402 non-null  int64 \n",
      " 32  v29_salaried        1285402 non-null  int64 \n",
      " 33  v29_self employed   1285402 non-null  int64 \n",
      " 34  v29_student         1285402 non-null  int64 \n",
      " 35  v29_unemployed      1285402 non-null  int64 \n",
      " 36  v36_CUSTOMER        1285402 non-null  int64 \n",
      " 37  v36_FINNONE         1285402 non-null  int64 \n",
      " 38  v36_MDM             1285402 non-null  int64 \n",
      " 39  v36_MDM_CORP        1285402 non-null  int64 \n",
      " 40  v54_female          1285402 non-null  int64 \n",
      " 41  v54_male            1285402 non-null  int64 \n",
      " 42  v54_other           1285402 non-null  int64 \n",
      " 43  v81_N               1285402 non-null  int64 \n",
      " 44  v81_Y               1285402 non-null  int64 \n",
      " 45  v100_1              1285402 non-null  int64 \n",
      " 46  v100_2              1285402 non-null  int64 \n",
      " 47  v100_3              1285402 non-null  int64 \n",
      " 48  v100_4              1285402 non-null  int64 \n",
      " 49  v101_Rural          1285402 non-null  int64 \n",
      " 50  v101_Tier 1         1285402 non-null  int64 \n",
      " 51  v101_Tier 2         1285402 non-null  int64 \n",
      " 52  v101_Tier 3         1285402 non-null  int64 \n",
      " 53  v101_Tier 4         1285402 non-null  int64 \n",
      " 54  v101_Tier 5         1285402 non-null  int64 \n",
      " 55  v101_Tier 6         1285402 non-null  int64 \n",
      " 56  v101_Tier 7         1285402 non-null  int64 \n",
      " 57  v101_Tier 8         1285402 non-null  int64 \n",
      " 58  v102_Homemaker      1285402 non-null  int64 \n",
      " 59  v102_Minor          1285402 non-null  int64 \n",
      " 60  v102_Other          1285402 non-null  int64 \n",
      " 61  v102_Retired        1285402 non-null  int64 \n",
      " 62  v102_Salaried       1285402 non-null  int64 \n",
      " 63  v102_Self_Employed  1285402 non-null  int64 \n",
      " 64  v102_Student        1285402 non-null  int64 \n",
      " 65  v102_Unemployed     1285402 non-null  int64 \n",
      "dtypes: int64(64), object(2)\n",
      "memory usage: 647.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_demo_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Action History Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_action_history = pd.read_csv('train_action_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1\t Slot Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_slots_vectorized(df):\n",
    "    \"\"\"\n",
    "    Converts send_timestamp and open_timestamp to time slots (1-28) in a vectorized way.\n",
    "    - Time slots: 3-hour windows from 9AM to 9PM daily (4 slots/day  7 days = 28 slots).\n",
    "    - Slots outside 9AM-9PM are set to `None`.\n",
    "    \"\"\"\n",
    "    for col in ['send_timestamp', 'open_timestamp']:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        dt_series = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "        day_of_week = dt_series.dt.dayofweek  \n",
    "        total_minutes = dt_series.dt.hour * 60 + dt_series.dt.minute\n",
    "        valid_mask = (total_minutes >= 540) & (total_minutes < 1260)  \n",
    "        slot_in_day = ((total_minutes - 540) // 180).astype('Int64')  \n",
    "        slot_number = (day_of_week * 4 + slot_in_day + 1).where(valid_mask, pd.NA) \n",
    "        \n",
    "        df[f'{col}_slot'] = slot_number.astype('Int64')  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.2\tOffer ID and Sub-ID Frequency Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_open_ratio_with_slot(df, feature_name, slot_column='send_slot'):\n",
    "    \"\"\"\n",
    "    Encodes a feature (e.g., Offer_id) with: (open_ratio)  (slot_number).\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - feature_name: Name of the feature to encode (e.g., 'Offer_id').\n",
    "    - slot_column: Name of the column containing slot numbers (e.g., 'send_slot').\n",
    "    \n",
    "    Returns:\n",
    "    - Series with encoded values.\n",
    "    \"\"\"\n",
    "    df['is_opened'] = df['open_timestamp_slot'].notna().astype(int)\n",
    "    open_ratio = df.groupby(feature_name)['is_opened'].transform('mean')\n",
    "    encoded_value = open_ratio * df[slot_column]\n",
    "    df.drop('is_opened', axis=1, inplace=True)\n",
    "    \n",
    "    return encoded_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_slots = add_time_slots_vectorized(train_action_history)\n",
    "df_train_slots.drop(columns=['batch_id'], inplace=True)\n",
    "df_train_slots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offer_id = encode_open_ratio_with_slot(df_train_slots, 'Offer_id', 'send_timestamp_slot')\n",
    "Offer_subid = encode_open_ratio_with_slot(df_train_slots, 'Offer_subid', 'send_timestamp_slot')\n",
    "df_train_slots['Offer_id'] = Offer_id\n",
    "df_train_slots['Offer_subid'] = Offer_subid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_removed = df_train_slots[df_train_slots['customer_code'].isin(train_demo_encoded['CUSTOMER_CODE'])]\n",
    "df_train_removed['send_timestamp_slot'].hist(bins=50)\n",
    "value_counts = df_train_removed['send_timestamp_slot'].value_counts(normalize=True) * 100\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.3  Sampling Methadology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 18: Opened/Sent = 120832/469343 = 0.26\n",
      "Class 10: Opened/Sent = 114784/458283 = 0.25\n",
      "Class 14: Opened/Sent = 114298/440710 = 0.26\n",
      "Class 23: Opened/Sent = 100699/433764 = 0.23\n",
      "Class 19: Opened/Sent = 99646/432173 = 0.23\n",
      "Class 11: Opened/Sent = 98334/422314 = 0.23\n",
      "Class 21: Opened/Sent = 95481/403548 = 0.24\n",
      "Class 22: Opened/Sent = 95725/384060 = 0.25\n",
      "Class 13: Opened/Sent = 91574/378495 = 0.24\n",
      "Class 15: Opened/Sent = 81718/375423 = 0.22\n",
      "Class 2: Opened/Sent = 93506/355321 = 0.26\n",
      "Class 6: Opened/Sent = 89822/351989 = 0.26\n",
      "Class 26: Opened/Sent = 88525/349715 = 0.25\n",
      "Class 3: Opened/Sent = 83523/348825 = 0.24\n",
      "Class 5: Opened/Sent = 86946/346244 = 0.25\n",
      "Class 17: Opened/Sent = 86589/345755 = 0.25\n",
      "Class 7: Opened/Sent = 78849/339061 = 0.23\n",
      "Class 27: Opened/Sent = 74007/320349 = 0.23\n",
      "Class 1: Opened/Sent = 70455/290874 = 0.24\n",
      "Class 25: Opened/Sent = 66097/284834 = 0.23\n",
      "Class 9: Opened/Sent = 58511/234591 = 0.25\n",
      "Class 16: Opened/Sent = 22088/136978 = 0.16\n",
      "Class 24: Opened/Sent = 18581/99605 = 0.19\n",
      "Class 4: Opened/Sent = 19901/96181 = 0.21\n",
      "Class 20: Opened/Sent = 18146/94894 = 0.19\n",
      "Class 12: Opened/Sent = 18580/94849 = 0.20\n",
      "Class 28: Opened/Sent = 18239/91693 = 0.20\n",
      "Class 8: Opened/Sent = 17141/87557 = 0.20\n"
     ]
    }
   ],
   "source": [
    "df = df_train_removed\n",
    "\n",
    "# 1. Calculate the original sent counts for each class\n",
    "class_sent_counts = df['send_timestamp_slot'].value_counts().to_dict()\n",
    "\n",
    "# 2. Identify opened entries (drop NaN in 'open_timestamp_slot')\n",
    "df_opened = df.dropna(subset=['open_timestamp_slot']).copy()\n",
    "\n",
    "# 3. For each class, calculate how many opened entries to retain to preserve the original ratio\n",
    "final_samples = []\n",
    "for cls, sent_count in class_sent_counts.items():\n",
    "    # Get opened entries for this class\n",
    "    cls_opened = df_opened[df_opened['send_timestamp_slot'] == cls]\n",
    "    opened_count = len(cls_opened)\n",
    "    \n",
    "    # Calculate the original opened ratio for this class\n",
    "    original_opened_ratio = opened_count / sent_count  # e.g., 0.3 for 30% opened\n",
    "    \n",
    "    # Retain the same ratio of opened entries relative to the original sent count\n",
    "    # Example: If original ratio is 30%, retain 30% of the original sent count\n",
    "    desired_retained = int(sent_count * original_opened_ratio)\n",
    "    \n",
    "    # If fewer opened entries exist than desired, take all available\n",
    "    desired_retained = min(desired_retained, opened_count)\n",
    "    \n",
    "    # Sample without replacement\n",
    "    sampled = cls_opened.sample(n=desired_retained, replace=False, random_state=42)\n",
    "    final_samples.append(sampled)\n",
    "\n",
    "# Combine results into the final DataFrame\n",
    "final_df = pd.concat(final_samples)\n",
    "\n",
    "# Verify the ratios\n",
    "for cls in class_sent_counts:\n",
    "    sent = class_sent_counts[cls]\n",
    "    opened = len(final_df[final_df['send_timestamp_slot'] == cls])\n",
    "    print(f\"Class {cls}: Opened/Sent = {opened}/{sent} = {opened/sent:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_removed_sampled = final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.4\t One hot encoding of Product category and sub category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode product_category and sub_category\n",
    "df_train_removed_sampled = pd.get_dummies(df_train_removed_sampled, columns=['product_category'], prefix_sep='_')\n",
    "df_train_removed_sampled = pd.get_dummies(df_train_removed_sampled, columns=['product_sub_category'], prefix_sep='_')\n",
    "\n",
    "df_train_removed_sampled = df_train_removed_sampled * 1\n",
    "\n",
    "df_train_removed_sampled_encoded = df_train_removed_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_code</th>\n",
       "      <th>Offer_id</th>\n",
       "      <th>Offer_subid</th>\n",
       "      <th>send_timestamp</th>\n",
       "      <th>open_timestamp</th>\n",
       "      <th>send_timestamp_slot</th>\n",
       "      <th>open_timestamp_slot</th>\n",
       "      <th>product_category_ASSETS</th>\n",
       "      <th>product_category_CC_ACQ_SECURED</th>\n",
       "      <th>product_category_CC_ACQ_UNSECURED</th>\n",
       "      <th>...</th>\n",
       "      <th>product_sub_category_SWYP_ACQ</th>\n",
       "      <th>product_sub_category_SWYP_UPGRADE</th>\n",
       "      <th>product_sub_category_TACTICAL</th>\n",
       "      <th>product_sub_category_TOPICAL</th>\n",
       "      <th>product_sub_category_TURBO-SA XSELL</th>\n",
       "      <th>product_sub_category_UNSECURED_ACQ</th>\n",
       "      <th>product_sub_category_UPI</th>\n",
       "      <th>product_sub_category_VISTARA_ACQ</th>\n",
       "      <th>product_sub_category_VISTARA_UPGRADE</th>\n",
       "      <th>product_sub_category_VKYC COMPLETION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1580950</th>\n",
       "      <td>10a735a2f24dab28d8d4b630b518c35d7e0e5209661203...</td>\n",
       "      <td>4.183784</td>\n",
       "      <td>4.32899</td>\n",
       "      <td>2024-11-08T13:21:26.000Z</td>\n",
       "      <td>2024-11-08T14:34:20.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408299</th>\n",
       "      <td>fdea22ee97dc048ae6957aaa84cde1efd65d5331ff6a1b...</td>\n",
       "      <td>4.898467</td>\n",
       "      <td>5.022439</td>\n",
       "      <td>2024-08-30T12:06:39.000Z</td>\n",
       "      <td>2024-08-30T16:00:54.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7569560</th>\n",
       "      <td>65c6ef44ffb0a527c5023f8579e5bde63cc912c21e8f3a...</td>\n",
       "      <td>2.718348</td>\n",
       "      <td>2.6195</td>\n",
       "      <td>2024-11-29T12:01:20.000Z</td>\n",
       "      <td>2024-11-29T18:04:50.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466385</th>\n",
       "      <td>775f6565a6a9597985bc2175fe5607006542e04c2b2f04...</td>\n",
       "      <td>4.541515</td>\n",
       "      <td>4.541515</td>\n",
       "      <td>2024-07-26T13:36:01.000Z</td>\n",
       "      <td>2024-07-26T19:14:00.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286322</th>\n",
       "      <td>bb49f6a18962c9eaba6cb95a412443de110d417a1e1135...</td>\n",
       "      <td>5.522585</td>\n",
       "      <td>5.458156</td>\n",
       "      <td>2024-09-13T13:17:05.000Z</td>\n",
       "      <td>2024-09-13T13:19:24.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             customer_code  Offer_id  \\\n",
       "1580950  10a735a2f24dab28d8d4b630b518c35d7e0e5209661203...  4.183784   \n",
       "7408299  fdea22ee97dc048ae6957aaa84cde1efd65d5331ff6a1b...  4.898467   \n",
       "7569560  65c6ef44ffb0a527c5023f8579e5bde63cc912c21e8f3a...  2.718348   \n",
       "5466385  775f6565a6a9597985bc2175fe5607006542e04c2b2f04...  4.541515   \n",
       "286322   bb49f6a18962c9eaba6cb95a412443de110d417a1e1135...  5.522585   \n",
       "\n",
       "         Offer_subid            send_timestamp            open_timestamp  \\\n",
       "1580950      4.32899  2024-11-08T13:21:26.000Z  2024-11-08T14:34:20.000Z   \n",
       "7408299     5.022439  2024-08-30T12:06:39.000Z  2024-08-30T16:00:54.000Z   \n",
       "7569560       2.6195  2024-11-29T12:01:20.000Z  2024-11-29T18:04:50.000Z   \n",
       "5466385     4.541515  2024-07-26T13:36:01.000Z  2024-07-26T19:14:00.000Z   \n",
       "286322      5.458156  2024-09-13T13:17:05.000Z  2024-09-13T13:19:24.000Z   \n",
       "\n",
       "         send_timestamp_slot  open_timestamp_slot  product_category_ASSETS  \\\n",
       "1580950                   18                   18                        0   \n",
       "7408299                   18                   19                        0   \n",
       "7569560                   18                   20                        0   \n",
       "5466385                   18                   20                        0   \n",
       "286322                    18                   18                        0   \n",
       "\n",
       "         product_category_CC_ACQ_SECURED  product_category_CC_ACQ_UNSECURED  \\\n",
       "1580950                                0                                  0   \n",
       "7408299                                0                                  0   \n",
       "7569560                                0                                  0   \n",
       "5466385                                0                                  0   \n",
       "286322                                 0                                  0   \n",
       "\n",
       "         ...  product_sub_category_SWYP_ACQ  \\\n",
       "1580950  ...                              0   \n",
       "7408299  ...                              0   \n",
       "7569560  ...                              0   \n",
       "5466385  ...                              0   \n",
       "286322   ...                              0   \n",
       "\n",
       "         product_sub_category_SWYP_UPGRADE  product_sub_category_TACTICAL  \\\n",
       "1580950                                  0                              0   \n",
       "7408299                                  0                              0   \n",
       "7569560                                  0                              0   \n",
       "5466385                                  0                              0   \n",
       "286322                                   0                              0   \n",
       "\n",
       "         product_sub_category_TOPICAL  product_sub_category_TURBO-SA XSELL  \\\n",
       "1580950                             0                                    0   \n",
       "7408299                             0                                    0   \n",
       "7569560                             0                                    0   \n",
       "5466385                             1                                    0   \n",
       "286322                              0                                    1   \n",
       "\n",
       "         product_sub_category_UNSECURED_ACQ  product_sub_category_UPI  \\\n",
       "1580950                                   0                         0   \n",
       "7408299                                   0                         0   \n",
       "7569560                                   0                         0   \n",
       "5466385                                   0                         0   \n",
       "286322                                    0                         0   \n",
       "\n",
       "         product_sub_category_VISTARA_ACQ  \\\n",
       "1580950                                 0   \n",
       "7408299                                 0   \n",
       "7569560                                 0   \n",
       "5466385                                 0   \n",
       "286322                                  0   \n",
       "\n",
       "         product_sub_category_VISTARA_UPGRADE  \\\n",
       "1580950                                     0   \n",
       "7408299                                     0   \n",
       "7569560                                     0   \n",
       "5466385                                     0   \n",
       "286322                                      0   \n",
       "\n",
       "         product_sub_category_VKYC COMPLETION  \n",
       "1580950                                     0  \n",
       "7408299                                     0  \n",
       "7569560                                     0  \n",
       "5466385                                     0  \n",
       "286322                                      0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_removed_sampled_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.5 Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "demograph = train_demo_encoded\n",
    "action = df_train_removed_sampled_encoded\n",
    "\n",
    "# Convert date columns to datetime objects\n",
    "action['send_timestamp'] = pd.to_datetime(action['send_timestamp'])\n",
    "demograph['batch_date'] = pd.to_datetime(demograph['batch_date'])\n",
    "\n",
    "# Assuming IST timezone for both DataFrames\n",
    "action['send_timestamp'] = action['send_timestamp'].dt.tz_convert('Asia/Calcutta') if action['send_timestamp'].dt.tz is not None else action['send_timestamp'].dt.tz_localize('Asia/Calcutta')\n",
    "demograph['batch_date'] = demograph['batch_date'].dt.tz_convert('Asia/Calcutta') if demograph['batch_date'].dt.tz is not None else demograph['batch_date'].dt.tz_localize('Asia/Calcutta')\n",
    "\n",
    "# Sort both DataFrames by the key columns\n",
    "action = action.sort_values(by=['customer_code', 'send_timestamp'])\n",
    "demograph = demograph.sort_values(by=['CUSTOMER_CODE', 'batch_date'])\n",
    "\n",
    "# Ensure both left and right keys are sorted\n",
    "action = action.sort_values(by='send_timestamp')\n",
    "demograph = demograph.sort_values(by='batch_date')\n",
    "\n",
    "# Perform the merge using merge_asof\n",
    "merged_data = pd.merge_asof(\n",
    "    action,\n",
    "    demograph,\n",
    "    left_on='send_timestamp',\n",
    "    right_on='batch_date',\n",
    "    left_by='customer_code',\n",
    "    right_by='CUSTOMER_CODE',\n",
    "    direction='backward'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.6  One hot encoding of Send_slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_data\n",
    "df = pd.get_dummies(df, columns=['send_timestamp_slot'], prefix_sep='_',dtype=int)\n",
    "df.drop(columns=['open_timestamp','open_timestamp_slot','CUSTOMER_CODE','batch_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in the cleaned dataframe: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove rows containing NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Print the number of NaN values in the cleaned dataframe\n",
    "print(\"Number of NaN values in the cleaned dataframe:\", df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Training Set Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1 Date Range: 2024-06-01 15:02:41+05:30 to 2024-09-01 15:02:24+05:30\n",
      "X_2 Date Range: 2024-07-01 15:06:41+05:30 to 2024-10-01 15:02:39+05:30\n",
      "X_3 Date Range: 2024-08-01 15:03:26+05:30 to 2024-11-01 15:02:36+05:30\n",
      "\n",
      "Shape of X_1: (984271, 200)\n",
      "Shape of X_2: (1057767, 200)\n",
      "Shape of X_3: (1113456, 200)\n"
     ]
    }
   ],
   "source": [
    "# Convert send_timestamp to datetime and sort\n",
    "df['send_timestamp'] = pd.to_datetime(df['send_timestamp'])\n",
    "df = df.sort_values(by='send_timestamp')\n",
    "\n",
    "# Get the minimum timestamp in the data\n",
    "min_timestamp = df['send_timestamp'].min()\n",
    "max_timestamp = df['send_timestamp'].max()  # For validation\n",
    "\n",
    "# Define overlapping 3-month windows (starting 1 month apart)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# X_1: First 3 months (e.g., 2024-06-01 to 2024-09-01)\n",
    "X_1 = df[\n",
    "    (df['send_timestamp'] >= min_timestamp) & \n",
    "    (df['send_timestamp'] < min_timestamp + pd.DateOffset(months=3))\n",
    "]\n",
    "\n",
    "# X_2: Starts 1 month after X_1 (e.g., 2024-07-01 to 2024-10-01)\n",
    "X_2 = df[\n",
    "    (df['send_timestamp'] >= min_timestamp + pd.DateOffset(months=1)) & \n",
    "    (df['send_timestamp'] < min_timestamp + pd.DateOffset(months=4))\n",
    "]\n",
    "\n",
    "# X_3: Starts 2 months after X_1 (e.g., 2024-08-01 to 2024-11-01)\n",
    "X_3 = df[\n",
    "    (df['send_timestamp'] >= min_timestamp + pd.DateOffset(months=2)) & \n",
    "    (df['send_timestamp'] < min_timestamp + pd.DateOffset(months=5))\n",
    "]\n",
    "\n",
    "# Print results\n",
    "print(\"X_1 Date Range:\", X_1['send_timestamp'].min(), \"to\", X_1['send_timestamp'].max())\n",
    "print(\"X_2 Date Range:\", X_2['send_timestamp'].min(), \"to\", X_2['send_timestamp'].max())\n",
    "print(\"X_3 Date Range:\", X_3['send_timestamp'].min(), \"to\", X_3['send_timestamp'].max())\n",
    "print(\"\\nShape of X_1:\", X_1.shape)\n",
    "print(\"Shape of X_2:\", X_2.shape)\n",
    "print(\"Shape of X_3:\", X_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Target Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Windows:\n",
      "Y_1: 2024-09-01 00:00:23+05:30 to 2024-09-30 23:59:24+05:30 | Shape: (363805, 200)\n",
      "Y_2: 2024-10-01 00:00:06+05:30 to 2024-10-31 23:59:30+05:30 | Shape: (398791, 200)\n",
      "Y_3: 2024-11-01 00:00:08+05:30 to 2024-11-30 23:59:59+05:30 | Shape: (268244, 200)\n"
     ]
    }
   ],
   "source": [
    "# Convert send_timestamp to datetime and sort\n",
    "df['send_timestamp'] = pd.to_datetime(df['send_timestamp'])\n",
    "df = df.sort_values(by='send_timestamp')\n",
    "\n",
    "# Define key timestamps\n",
    "min_timestamp = df['send_timestamp'].min()  # 2024-06-01 15:02:41+05:30\n",
    "max_timestamp = df['send_timestamp'].max()  # 2024-12-01 01:30:18+05:30\n",
    "\n",
    "# --------------------------------------------------------\n",
    "y_start = pd.Timestamp('2024-09-01').tz_localize('Asia/Kolkata')  # Define start date\n",
    "\n",
    "Y_1 = df[\n",
    "    (df['send_timestamp'] >= y_start) &\n",
    "    (df['send_timestamp'] < y_start + pd.DateOffset(months=1))  # Sep 1 - Oct 1\n",
    "]\n",
    "\n",
    "Y_2 = df[\n",
    "    (df['send_timestamp'] >= y_start + pd.DateOffset(months=1)) &\n",
    "    (df['send_timestamp'] < y_start + pd.DateOffset(months=2))  # Oct 1 - Nov 1\n",
    "]\n",
    "\n",
    "Y_3 = df[\n",
    "    (df['send_timestamp'] >= y_start + pd.DateOffset(months=2)) &\n",
    "    (df['send_timestamp'] < y_start + pd.DateOffset(months=3))  # Nov 1 - Dec 1\n",
    "]\n",
    "\n",
    "\n",
    "print(\"\\nTest Windows:\")\n",
    "print(\"Y_1:\", Y_1['send_timestamp'].min(), \"to\", Y_1['send_timestamp'].max(), \"| Shape:\", Y_1.shape)\n",
    "print(\"Y_2:\", Y_2['send_timestamp'].min(), \"to\", Y_2['send_timestamp'].max(), \"| Shape:\", Y_2.shape)\n",
    "print(\"Y_3:\", Y_3['send_timestamp'].min(), \"to\", Y_3['send_timestamp'].max(), \"| Shape:\", Y_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1 Preprocessing X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'send_timestamp' column and select only numeric columns\n",
    "X_1.drop(columns=['send_timestamp'],inplace=True)\n",
    "X_1_merged = X_1.groupby('customer_code').mean().reset_index()\n",
    "\n",
    "X_2.drop(columns=['send_timestamp'],inplace=True)\n",
    "X_2_merged = X_2.groupby('customer_code').mean().reset_index()\n",
    "\n",
    "X_3.drop(columns=['send_timestamp'],inplace=True)\n",
    "X_3_merged = X_3.groupby('customer_code').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137915, 199)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns for Y_1\n",
    "columns_to_keep = ['customer_code'] + [col for col in Y_1.columns if col.startswith('send_timestamp_slot_')]\n",
    "Y_1 = Y_1[columns_to_keep]\n",
    "\n",
    "# Filter columns for Y_2\n",
    "columns_to_keep = ['customer_code'] + [col for col in Y_2.columns if col.startswith('send_timestamp_slot_')]\n",
    "Y_2 = Y_2[columns_to_keep]\n",
    "\n",
    "# Filter columns for Y_3\n",
    "columns_to_keep = ['customer_code'] + [col for col in Y_3.columns if col.startswith('send_timestamp_slot_')]\n",
    "Y_3 = Y_3[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1_merged = Y_1.groupby('customer_code').mean().reset_index()\n",
    "Y_2_merged = Y_2.groupby('customer_code').mean().reset_index()\n",
    "Y_3_merged = Y_3.groupby('customer_code').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_filter_datasets(X_df, Y_df, customer_col='customer_code', verbose=True, keep_order=True):\n",
    "    \"\"\"\n",
    "    Aligns and filters two datasets to keep only common customers, optionally reordering Y to match X's sequence.\n",
    "    \n",
    "    Parameters:\n",
    "    X_df (DataFrame): First dataset with customer codes\n",
    "    Y_df (DataFrame): Second dataset with customer codes\n",
    "    customer_col (str): Name of customer code column (default: 'customer_code')\n",
    "    verbose (bool): Whether to print progress messages (default: True)\n",
    "    keep_order (bool): Whether to maintain X's customer order in Y (default: True)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X_filtered, Y_filtered) - Aligned and filtered DataFrames\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if customer_col not in X_df.columns:\n",
    "        raise ValueError(f\"Column '{customer_col}' not found in X dataframe\")\n",
    "    if customer_col not in Y_df.columns:\n",
    "        raise ValueError(f\"Column '{customer_col}' not found in Y dataframe\")\n",
    "\n",
    "    # Find common customers\n",
    "    common_mask = X_df[customer_col].isin(Y_df[customer_col])\n",
    "    common_customers = X_df.loc[common_mask, customer_col].unique()\n",
    "    \n",
    "    if verbose:\n",
    "        original_X = len(X_df)\n",
    "        original_Y = len(Y_df)\n",
    "        print(f\"Original sizes: X={original_X}, Y={original_Y}\")\n",
    "        print(f\"Found {len(common_customers)} common customers\")\n",
    "\n",
    "    # Filter both datasets\n",
    "    X_filtered = X_df[X_df[customer_col].isin(common_customers)]\n",
    "    Y_filtered = Y_df[Y_df[customer_col].isin(common_customers)]\n",
    "\n",
    "    if keep_order:\n",
    "        # Create ordering reference from X\n",
    "        order_df = pd.DataFrame({\n",
    "            customer_col: X_filtered[customer_col],\n",
    "            '__sort_key__': range(len(X_filtered))\n",
    "        })\n",
    "\n",
    "        # Merge with Y to inherit order\n",
    "        Y_filtered = (\n",
    "            order_df\n",
    "            .merge(Y_filtered, on=customer_col, how='left')\n",
    "            .sort_values('__sort_key__')\n",
    "            .drop(columns='__sort_key__')\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Final sizes: X={len(X_filtered)}, Y={len(Y_filtered)}\")\n",
    "        print(f\"Missing in Y after alignment: {Y_filtered[customer_col].isna().sum()}\")\n",
    "\n",
    "    return X_filtered, Y_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sizes: X=137915, Y=125584\n",
      "Found 101513 common customers\n",
      "Final sizes: X=101513, Y=101513\n",
      "Missing in Y after alignment: 0\n",
      "Original sizes: X=155969, Y=121330\n",
      "Found 94881 common customers\n",
      "Final sizes: X=94881, Y=94881\n",
      "Missing in Y after alignment: 0\n",
      "Original sizes: X=177855, Y=93269\n",
      "Found 77776 common customers\n",
      "Final sizes: X=77776, Y=77776\n",
      "Missing in Y after alignment: 0\n"
     ]
    }
   ],
   "source": [
    "X_1_final, Y_1_final = align_and_filter_datasets(X_1_merged, Y_1_merged)\n",
    "X_2_final, Y_2_final = align_and_filter_datasets(X_2_merged, Y_2_merged)\n",
    "X_3_final, Y_3_final = align_and_filter_datasets(X_3_merged, Y_3_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_30628\\1821789859.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_1_final.drop(columns=['customer_code'], inplace=True)\n",
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_30628\\1821789859.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_2_final.drop(columns=['customer_code'], inplace=True)\n",
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_30628\\1821789859.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_3_final.drop(columns=['customer_code'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_1_final.drop(columns=['customer_code'], inplace=True)\n",
    "X_2_final.drop(columns=['customer_code'], inplace=True)\n",
    "X_3_final.drop(columns=['customer_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1_final.drop(columns=['customer_code'], inplace=True)\n",
    "Y_2_final.drop(columns=['customer_code'], inplace=True)\n",
    "Y_3_final.drop(columns=['customer_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.concat([X_1_final, X_2_final, X_3_final], axis=0)\n",
    "Y_final = pd.concat([Y_1_final, Y_2_final, Y_3_final], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((274170, 198), (274170, 28))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape, Y_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiliting data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spiliting data set into train and test using strtify= y as the data set is highly imbalanced\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_final,Y_final, train_size = 0.8, random_state = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Scale the training data\n",
    "X_train_scaled = robust_scaler.fit_transform(X_train)\n",
    "X_test_scaled = robust_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1  Stacking Model BM : \"RandomForest\" and MM : \"XGBoost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model (RandomForestRegressor)\n",
    "base_model = RandomForestRegressor(random_state=1055, n_jobs=-1)\n",
    "\n",
    "# Define the meta-model (XGBRegressor)\n",
    "meta_model = XGBRegressor(random_state=1055, n_jobs=-1)\n",
    "\n",
    "# Train the base model\n",
    "base_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate base model predictions on the training set\n",
    "base_predictions_train = base_model.predict(X_train_scaled)\n",
    "\n",
    "# Combine the original features with the base model predictions\n",
    "stacked_features_train = np.hstack((X_train_scaled, base_predictions_train))\n",
    "\n",
    "# Train the meta-model on the stacked features\n",
    "meta_model.fit(stacked_features_train, y_train)\n",
    "\n",
    "# Generate base model predictions on the test set\n",
    "base_predictions_test = base_model.predict(X_test_scaled)\n",
    "\n",
    "# Combine the original features with the base model predictions for the test set\n",
    "stacked_features_test = np.hstack((X_test_scaled, base_predictions_test))\n",
    "\n",
    "# Make predictions using the meta-model\n",
    "y_pred = meta_model.predict(stacked_features_test)\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error (or your custom MAP scorer)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(ranked_slots, actual_relevance, k=28):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP) for a single prediction.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_slots (list): Ranked list of slots (e.g., ['slot_11', 'slot_23', ...]).\n",
    "    actual_relevance (array): Binary array indicating relevant slots (e.g., [0, 0, 1, ...]).\n",
    "    k (int): Number of slots to consider (default: 28).\n",
    "\n",
    "    Returns:\n",
    "    float: MAP score.\n",
    "    \"\"\"\n",
    "    # Convert ranked_slots to indices (e.g., ['slot_11', 'slot_23'] -> [10, 22])\n",
    "    ranked_indices = [int(slot.split('_')[1]) - 1 for slot in ranked_slots]\n",
    "\n",
    "    # Initialize variables\n",
    "    relevant_count = 0\n",
    "    cumulative_precision = 0.0\n",
    "\n",
    "    # Iterate through the ranked slots\n",
    "    for i, slot_index in enumerate(ranked_indices[:k]):\n",
    "        if actual_relevance[slot_index] == 1:\n",
    "            relevant_count += 1\n",
    "            precision_at_i = relevant_count / (i + 1)\n",
    "            cumulative_precision += precision_at_i\n",
    "\n",
    "    # Calculate Average Precision (AP)\n",
    "    total_relevant = np.sum(actual_relevance)\n",
    "    if total_relevant == 0:\n",
    "        return 0.0  # No relevant slots, AP is 0\n",
    "    ap = cumulative_precision / total_relevant\n",
    "\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the base model\n",
    "# base_model = joblib.load('base_model.pkl')\n",
    "\n",
    "# # Load the meta model\n",
    "# meta_model = joblib.load('meta_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated MAP calculation for continuous values\n",
    "def calculate_map_continuous(y_true, y_pred, k=28):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP) for continuous predictions.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy array): Actual target values.\n",
    "    y_pred (numpy array): Predicted probabilities or scores.\n",
    "    k (int): Number of top slots to consider (default: 28).\n",
    "\n",
    "    Returns:\n",
    "    float: MAP score.\n",
    "    \"\"\"\n",
    "    ap_scores = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        # Sort indices by predicted values in descending order\n",
    "        sorted_indices = np.argsort(-y_pred[i])\n",
    "        \n",
    "        # Get top-k indices\n",
    "        top_k_indices = sorted_indices[:k]\n",
    "        \n",
    "        # Calculate precision at k for relevant slots\n",
    "        relevance = y_true[i][top_k_indices]\n",
    "        precision_at_k = relevance.cumsum() / np.arange(1, k + 1)\n",
    "        ap = (precision_at_k * relevance).sum() / relevance.sum() if relevance.sum() > 0 else 0\n",
    "        ap_scores.append(ap)\n",
    "    \n",
    "    return np.mean(ap_scores)\n",
    "\n",
    "# Generate ranked lists\n",
    "def rank_slots(predictions):\n",
    "    slot_names = [f\"slot_{i+1}\" for i in range(predictions.shape[1])]\n",
    "    ranked = []\n",
    "    for row in predictions:\n",
    "        # Pair slot names with probabilities and sort descendingly\n",
    "        sorted_slots = sorted(zip(slot_names, row), key=lambda x: -x[1])\n",
    "        # Extract slot names in order\n",
    "        ranked.append([slot for slot, _ in sorted_slots])\n",
    "    return ranked\n",
    "\n",
    "# Predict time slots\n",
    "def predict_time_slots(base_model, meta_model, input_data):\n",
    "    \"\"\"\n",
    "    Predicts the ranked time slots for a single input row using a stacking model.\n",
    "\n",
    "    Parameters:\n",
    "    base_model (sklearn model): Trained base regression model.\n",
    "    meta_model (sklearn model): Trained meta regression model.\n",
    "    input_data (array-like): Single row of input data (features).\n",
    "\n",
    "    Returns:\n",
    "    dict: Predicted probabilities and ranked slots.\n",
    "    \"\"\"\n",
    "    # Ensure input_data is a 2D array for prediction\n",
    "    input_array = np.array(input_data).reshape(1, -1)\n",
    "\n",
    "    # Step 1: Get base model prediction for the input row\n",
    "    base_prediction = base_model.predict(input_array).reshape(1, -1)\n",
    "\n",
    "    # Step 2: Combine original input with base prediction for meta-model\n",
    "    stacked_input = np.hstack((input_array, base_prediction))\n",
    "\n",
    "    # Step 3: Predict probabilities using the meta-model\n",
    "    predicted_probs = meta_model.predict(stacked_input).reshape(1, -1)\n",
    "\n",
    "    # Step 4: Rank slots by predicted probabilities\n",
    "    slot_names = [f\"slot_{i+1}\" for i in range(predicted_probs.shape[1])]\n",
    "    sorted_slots = sorted(zip(slot_names, predicted_probs[0]), key=lambda x: -x[1])\n",
    "\n",
    "    # Extract ranked slots and probabilities\n",
    "    ranked_slots = [slot for slot, _ in sorted_slots]\n",
    "    ranked_probs = [prob for _, prob in sorted_slots]\n",
    "\n",
    "    return {\n",
    "        \"ranked_slots\": ranked_slots,\n",
    "        \"ranked_probs\": ranked_probs\n",
    "    }\n",
    "    \n",
    "    # Predict time slots\n",
    "def predict_time_slots(base_model, meta_model, input_data):\n",
    "    \"\"\"\n",
    "    Predicts the ranked time slots for a single input row using a stacking model.\n",
    "\n",
    "    Parameters:\n",
    "    base_model (sklearn model): Trained base regression model.\n",
    "    meta_model (sklearn model): Trained meta regression model.\n",
    "    input_data (array-like): Single row of input data (features).\n",
    "\n",
    "    Returns:\n",
    "    dict: Predicted probabilities and ranked slots.\n",
    "    \"\"\"\n",
    "    # Ensure input_data is a 2D array for prediction\n",
    "    input_array = np.array(input_data).reshape(1, -1)\n",
    "\n",
    "    # Step 1: Get base model prediction for the input row\n",
    "    base_prediction = base_model.predict(input_array).reshape(1, -1)\n",
    "\n",
    "    # Step 2: Combine original input with base prediction for meta-model\n",
    "    stacked_input = np.hstack((input_array, base_prediction))\n",
    "\n",
    "    # Step 3: Predict probabilities using the meta-model\n",
    "    predicted_probs = meta_model.predict(stacked_input).reshape(1, -1)\n",
    "\n",
    "    # Step 4: Rank slots by predicted probabilities\n",
    "    slot_names = [f\"slot_{i+1}\" for i in range(predicted_probs.shape[1])]\n",
    "    sorted_slots = sorted(zip(slot_names, predicted_probs[0]), key=lambda x: -x[1])\n",
    "\n",
    "    # Extract ranked slots and probabilities\n",
    "    ranked_slots = [slot for slot, _ in sorted_slots]\n",
    "    ranked_probs = [prob for _, prob in sorted_slots]\n",
    "\n",
    "    return {\n",
    "        \"ranked_slots\": ranked_slots,\n",
    "        \"ranked_probs\": ranked_probs\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "map_score = calculate_map_continuous(y_test.values, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R (R-squared): {r2:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n",
    "\n",
    "ranked_predictions = rank_slots(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.2 Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def mean_average_precision(y_true, y_pred):\n",
    "    aps = []\n",
    "    for i in range(len(y_true)):\n",
    "        try:\n",
    "            # Convert to NumPy arrays if necessary\n",
    "            y_true_sample = np.array(y_true[i]) if isinstance(y_true, pd.Series) else y_true[i]\n",
    "            y_pred_sample = np.array(y_pred[i]) if isinstance(y_pred, pd.Series) else y_pred[i]\n",
    "\n",
    "            # Get true labels (indices of relevant items)\n",
    "            true_labels = np.where(y_true_sample == 1)[0]\n",
    "            pred_probs = y_pred_sample\n",
    "\n",
    "            # Sort predictions by probability\n",
    "            sorted_indices = np.argsort(pred_probs)[::-1]\n",
    "            sorted_true = y_true_sample[sorted_indices]\n",
    "\n",
    "            # Compute precision at each position\n",
    "            precision = np.cumsum(sorted_true) / (np.arange(len(sorted_true)) + 1)\n",
    "            average_precision = np.sum(precision * sorted_true) / np.sum(sorted_true)\n",
    "            aps.append(average_precision)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sample {i}: {e}\")\n",
    "            aps.append(0)  # Default to zero MAP for problematic samples\n",
    "    return np.mean(aps)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def map_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP) for multi-output regression.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): Ground truth (actual relevance).\n",
    "    y_pred (array-like): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    float: MAP score.\n",
    "    \"\"\"\n",
    "    n_outputs = y_true.shape[1]\n",
    "    map_scores = []\n",
    "\n",
    "    for i in range(n_outputs):\n",
    "        # Rank predictions for the current target\n",
    "        ranked_indices = np.argsort(-y_pred[:, i])  # Sort in descending order\n",
    "        ranked_relevance = y_true[:, i][ranked_indices]\n",
    "\n",
    "        # Calculate average precision for the current target\n",
    "        ap = average_precision_score(ranked_relevance, y_pred[:, i])\n",
    "        map_scores.append(ap)\n",
    "\n",
    "    # Return the mean of average precisions\n",
    "    return np.mean(map_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def build_model(input_shape, output_shape):\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    outputs = Dense(output_shape, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['mae'])  # Mean Absolute Error\n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "input_shape = X_train_scaled.shape[1]\n",
    "output_shape = y_train.shape[1]\n",
    "model = build_model(input_shape, output_shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Initialize and train the model\n",
    "multi_regressor = MultiOutputRegressor(\n",
    "    RandomForestRegressor(n_estimators=300,\n",
    "                         min_samples_split=100,\n",
    "                         min_samples_leaf=50,\n",
    "                         max_features=15,\n",
    "                         max_depth=10,\n",
    "                         n_jobs=-1,\n",
    "                         random_state=1055),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "multi_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities for all 28 slots (continuous values)\n",
    "y_pred_probs = multi_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Calculate Mean Average Precision (MAP)\n",
    "def calculate_map(y_true, y_pred):\n",
    "    ap_scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        ap_scores.append(average_precision_score(y_true[:, i], y_pred[:, i]))\n",
    "    return np.mean(ap_scores)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred_probs)\n",
    "mse = mean_squared_error(y_test, y_pred_probs)\n",
    "r2 = r2_score(y_test, y_pred_probs)\n",
    "map_score = calculate_map(y_test.values, y_pred_probs)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R (R-squared): {r2:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ranked lists\n",
    "def rank_slots(predictions):\n",
    "    slot_names = [f\"slot_{i+1}\" for i in range(28)]\n",
    "    ranked = []\n",
    "    for row in predictions:\n",
    "        # Pair slot names with probabilities and sort descendingly\n",
    "        sorted_slots = sorted(zip(slot_names, row), key=lambda x: -x[1])\n",
    "        # Extract slot names in order\n",
    "        ranked.append([slot for slot, _ in sorted_slots])\n",
    "    return ranked\n",
    "\n",
    "ranked_predictions = rank_slots(y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "def predict_time_slots(model, input_data, feature_names=None):\n",
    "    \"\"\"\n",
    "    Predicts the ranked time slots for a single input row using a RobustScaler.\n",
    "\n",
    "    Parameters:\n",
    "    model (sklearn model): Trained multi-output regression model.\n",
    "    scaler (RobustScaler): RobustScaler instance used during training.\n",
    "    input_data (array-like or dict): Single row of input data (features).\n",
    "    feature_names (list): List of feature names (required if input_data is a dict).\n",
    "\n",
    "    Returns:\n",
    "    dict: Predicted probabilities and ranked slots.\n",
    "    \"\"\"\n",
    "    # Convert input_data to a DataFrame if it's a dictionary\n",
    "    if isinstance(input_data, dict):\n",
    "        if feature_names is None:\n",
    "            raise ValueError(\"feature_names must be provided if input_data is a dictionary.\")\n",
    "        input_df = pd.DataFrame([input_data], columns=feature_names)\n",
    "    else:\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "\n",
    "    # Predict probabilities for all 28 slots\n",
    "    predicted_probs = model.predict(input_df)\n",
    "\n",
    "    # Rank slots by predicted probabilities\n",
    "    slot_names = [f\"slot_{i+1}\" for i in range(28)]\n",
    "    sorted_slots = sorted(zip(slot_names, predicted_probs[0]), key=lambda x: -x[1])\n",
    "\n",
    "    # Extract ranked slots and probabilities\n",
    "    ranked_slots = [slot for slot, _ in sorted_slots]\n",
    "    ranked_probs = [prob for _, prob in sorted_slots]\n",
    "\n",
    "    return {\n",
    "        \"ranked_slots\": ranked_slots,\n",
    "        \"ranked_probs\": ranked_probs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_map(ranked_slots, actual_relevance, k=28):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP) for a single prediction.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_slots (list): Ranked list of slots (e.g., ['slot_11', 'slot_23', ...]).\n",
    "    actual_relevance (array): Binary array indicatinga relevant slots (e.g., [0, 0, 1, ...]).\n",
    "    k (int): Number of slots to consider (default: 28).\n",
    "\n",
    "    Returns:\n",
    "    float: MAP score.\n",
    "    \"\"\"\n",
    "    # Convert ranked_slots to indices (e.g., ['slot_11', 'slot_23'] -> [10, 22])\n",
    "    ranked_indices = [int(slot.split('_')[1]) - 1 for slot in ranked_slots]\n",
    "\n",
    "    # Initialize variables\n",
    "    relevant_count = 0\n",
    "    cumulative_precision = 0.0\n",
    "\n",
    "    # Iterate through the ranked slots\n",
    "    for i, slot_index in enumerate(ranked_indices[:k]):\n",
    "        if actual_relevance[slot_index] == 1:\n",
    "            relevant_count += 1\n",
    "            precision_at_i = relevant_count / (i + 1)\n",
    "            cumulative_precision += precision_at_i\n",
    "\n",
    "    # Calculate Average Precision (AP)\n",
    "    total_relevant = np.sum(actual_relevance)\n",
    "    if total_relevant == 0:\n",
    "        return 0.0  # No relevant slots, AP is 0\n",
    "    ap = cumulative_precision / total_relevant\n",
    "\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_map_score = 0\n",
    "num_samples = 1000\n",
    "\n",
    "for i in range(num_samples):\n",
    "    input_data = X_train.iloc[i].values  # Single row as a NumPy array\n",
    "    result = predict_time_slots(model, input_data)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Row {i}:\")\n",
    "    print(\"Ranked Slots:\", result[\"ranked_slots\"])\n",
    "    print(\"Ranked Probabilities:\", result[\"ranked_probs\"])\n",
    "    print(\"Actual Relevance:\", y_train.iloc[i].values)\n",
    "    map_score = calculate_map(result[\"ranked_slots\"], y_train.iloc[i].values)\n",
    "    print(\"MAP Score:\", map_score)\n",
    "    print()\n",
    "    \n",
    "    total_map_score += map_score\n",
    "\n",
    "avg_map_score = total_map_score / num_samples\n",
    "print(f\"Average MAP Score for {num_samples} samples: {avg_map_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test action history data\n",
    "test_action_history = pd.read_csv('test_action_history.csv')  # Load the test action history dataset from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Slot Conversion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_slots_vectorized(df):\n",
    "    \"\"\"\n",
    "    Converts send_timestamp and open_timestamp to time slots (1-28) in a vectorized way.\n",
    "    - Time slots: 3-hour windows from 9AM to 9PM daily (4 slots/day  7 days = 28 slots).\n",
    "    - Slots outside 9AM-9PM are set to `None`.\n",
    "    \"\"\"\n",
    "    # Process both send and open timestamps\n",
    "    for col in ['send_timestamp', 'open_timestamp']:\n",
    "        # Skip if the column is not present in the DataFrame\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        # Convert the column to datetime, coercing errors to NaT (Not a Time)\n",
    "        dt_series = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "        \n",
    "        # Calculate day of the week (Monday=0, Sunday=6)\n",
    "        day_of_week = dt_series.dt.dayofweek\n",
    "        \n",
    "        # Calculate total minutes since midnight (hour * 60 + minute)\n",
    "        total_minutes = dt_series.dt.hour * 60 + dt_series.dt.minute\n",
    "        \n",
    "        # Time slot logic:\n",
    "        # - Valid time range: 9 AM (540 minutes) to 9 PM (1260 minutes)\n",
    "        valid_mask = (total_minutes >= 540) & (total_minutes < 1260)\n",
    "        \n",
    "        # Calculate slot within the day (0-3, representing 9AM-12PM, 12PM-3PM, etc.)\n",
    "        slot_in_day = ((total_minutes - 540) // 180).astype('Int64')  # Int64 handles NaN\n",
    "        \n",
    "        # Calculate the overall slot number (1-28) based on day of the week and slot in day\n",
    "        slot_number = (day_of_week * 4 + slot_in_day + 1).where(valid_mask, pd.NA)  # 1-28 or NA\n",
    "        \n",
    "        # Add the calculated slot number as a new column in the DataFrame\n",
    "        df[f'{col}_slot'] = slot_number.astype('Int64')  # Use pandas' nullable integer type\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Feature with Open Ratio and Slot Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_open_ratio_with_slot(df, feature_name, slot_column='send_slot'):\n",
    "    \"\"\"\n",
    "    Encodes a feature (e.g., Offer_id) with: (open_ratio)  (slot_number).\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - feature_name: Name of the feature to encode (e.g., 'Offer_id').\n",
    "    - slot_column: Name of the column containing slot numbers (e.g., 'send_slot').\n",
    "    \n",
    "    Returns:\n",
    "    - Series with encoded values.\n",
    "    \"\"\"\n",
    "    # Create a temporary column to indicate whether the feature was opened\n",
    "    # 'is_opened' is 1 if 'open_timestamp_slot' is not NaN, otherwise 0\n",
    "    df['is_opened'] = df['open_timestamp_slot'].notna().astype(int)\n",
    "    \n",
    "    # Calculate the open ratio for the feature\n",
    "    # The open ratio is the mean of 'is_opened' grouped by the feature (e.g., Offer_id)\n",
    "    open_ratio = df.groupby(feature_name)['is_opened'].transform('mean')\n",
    "    \n",
    "    # Multiply the open ratio by the slot number to get the encoded value\n",
    "    encoded_value = open_ratio * df[slot_column]\n",
    "    \n",
    "    # Cleanup: Drop the temporary 'is_opened' column as it's no longer needed\n",
    "    df.drop('is_opened', axis=1, inplace=True)\n",
    "    \n",
    "    # Return the encoded values as a Series\n",
    "    return encoded_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and Feature Engineering\n",
    "\n",
    "This cell performs several preprocessing steps, including:\n",
    "\n",
    "1) Adding time slots to the test action history data.\n",
    "\n",
    "2) Dropping unnecessary columns.\n",
    "\n",
    "3) Encoding Offer_id and Offer_subid using the encode_open_ratio_with_slot function.\n",
    "\n",
    "4) Filtering rows based on customer codes present in the demographics data.\n",
    "\n",
    "5) One-hot encoding categorical columns (product_category and product_sub_category).\n",
    "\n",
    "6) Visualizing the distribution of send_timestamp_slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time slots to the test action history data\n",
    "df_test_slots = add_time_slots_vectorized(test_action_history)\n",
    "\n",
    "# Drop the 'batch_id' column as it is no longer needed\n",
    "df_test_slots.drop(columns=['batch_id'], inplace=True)\n",
    "\n",
    "# Encode 'Offer_id' and 'Offer_subid' using the open ratio and slot number\n",
    "Offer_id = encode_open_ratio_with_slot(df_test_slots, 'Offer_id', 'send_timestamp_slot')\n",
    "Offer_subid = encode_open_ratio_with_slot(df_test_slots, 'Offer_subid', 'send_timestamp_slot')\n",
    "\n",
    "# Add the encoded values back to the DataFrame\n",
    "df_test_slots['Offer_id'] = Offer_id\n",
    "df_test_slots['Offer_subid'] = Offer_subid\n",
    "\n",
    "# Remove rows where 'customer_code' is not present in the demographics data\n",
    "test_demo_encoded1 = pd.read_csv('test_demo_encoded1.csv')\n",
    "df_test_slots = df_test_slots[df_test_slots['customer_code'].isin(test_demo_encoded1['CUSTOMER_CODE'])]\n",
    "\n",
    "# One-hot encode 'product_category' and 'product_sub_category'\n",
    "df_test_slots = pd.get_dummies(df_test_slots, columns=['product_category'], prefix_sep='_')\n",
    "df_test_slots = pd.get_dummies(df_test_slots, columns=['product_sub_category'], prefix_sep='_')\n",
    "\n",
    "# Convert boolean values from one-hot encoding to integers (1 or 0)\n",
    "df_test_slots = df_test_slots * 1\n",
    "\n",
    "# Create a copy of the DataFrame for further analysis\n",
    "df_test_removed = df_test_slots\n",
    "\n",
    "# Visualize the distribution of 'send_timestamp_slot'\n",
    "df_test_removed['send_timestamp_slot'].hist(bins=50)\n",
    "\n",
    "# Calculate the percentage distribution of 'send_timestamp_slot'\n",
    "value_counts = df_test_removed['send_timestamp_slot'].value_counts(normalize=True) * 100\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligning Columns Between Training and Test Data\n",
    "This cell ensures that the test data (df_test_removed) has the same columns as the training data (df_train). If any columns are missing in the test data, they are added with default values of 0. This step is crucial for ensuring compatibility between the training and test datasets before model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the preprocessed test data to a new variable for clarity\n",
    "df = df_test_removed\n",
    "\n",
    "# Display information about the DataFrame (e.g., columns, data types, non-null counts)\n",
    "df.info()\n",
    "\n",
    "# Load the demographics data\n",
    "demograph = pd.read_csv('test_demo_encoded1.csv')\n",
    "\n",
    "# Assign the preprocessed test data to the variable 'action' for further use\n",
    "action = df\n",
    "\n",
    "# Load the training data (one-hot encoded before merging)\n",
    "df_train = pd.read_csv('one_hot_encoded_before_merging.csv')\n",
    "\n",
    "def align_columns(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Ensure that test_df has the same columns as train_df.\n",
    "    If a column is missing in test_df, add it with all values set to 0.\n",
    "\n",
    "    Parameters:\n",
    "    train_df (pd.DataFrame): Training data with encoded columns.\n",
    "    test_df (pd.DataFrame): Test data with encoded columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Test data with aligned columns.\n",
    "    \"\"\"\n",
    "    # Get the columns in train_df that are missing in test_df\n",
    "    missing_columns = set(train_df.columns) - set(test_df.columns)\n",
    "\n",
    "    # Add missing columns to test_df with all values set to 0\n",
    "    for col in missing_columns:\n",
    "        test_df[col] = 0\n",
    "\n",
    "    # Reorder columns in test_df to match train_df\n",
    "    test_df = test_df[train_df.columns]\n",
    "\n",
    "    return test_df\n",
    "\n",
    "# Align the test data columns with the training data columns\n",
    "df = align_columns(df_train, df)\n",
    "\n",
    "# Display the aligned DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Action History with Demographics Data\n",
    "This cell merges the action history data (action) with the demographics data (demograph) using a time-based merge (merge_asof). The merge is performed based on the send_timestamp and batch_date columns, ensuring that the closest previous demographic data is matched to each action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'send_timestamp' and 'batch_date' columns to datetime objects\n",
    "action['send_timestamp'] = pd.to_datetime(action['send_timestamp'])\n",
    "demograph['batch_date'] = pd.to_datetime(demograph['batch_date'])\n",
    "\n",
    "# Convert timestamps to IST timezone (Asia/Calcutta)\n",
    "# If the timestamps already have a timezone, convert it; otherwise, localize it\n",
    "action['send_timestamp'] = (\n",
    "    action['send_timestamp'].dt.tz_convert('Asia/Calcutta') \n",
    "    if action['send_timestamp'].dt.tz is not None \n",
    "    else action['send_timestamp'].dt.tz_localize('Asia/Calcutta')\n",
    ")\n",
    "\n",
    "demograph['batch_date'] = (\n",
    "    demograph['batch_date'].dt.tz_convert('Asia/Calcutta') \n",
    "    if demograph['batch_date'].dt.tz is not None \n",
    "    else demograph['batch_date'].dt.tz_localize('Asia/Calcutta')\n",
    ")\n",
    "\n",
    "# Sort the action DataFrame by 'customer_code' and 'send_timestamp'\n",
    "action = action.sort_values(by=['customer_code', 'send_timestamp'])\n",
    "\n",
    "# Sort the demographics DataFrame by 'CUSTOMER_CODE' and 'batch_date'\n",
    "demograph = demograph.sort_values(by=['CUSTOMER_CODE', 'batch_date'])\n",
    "\n",
    "# Ensure both DataFrames are sorted by their respective timestamp columns\n",
    "action = action.sort_values(by='send_timestamp')\n",
    "demograph = demograph.sort_values(by='batch_date')\n",
    "\n",
    "# Perform the merge using merge_asof\n",
    "# This merges the action and demographics DataFrames based on the closest previous timestamp\n",
    "merged_df = pd.merge_asof(\n",
    "    action,  # Left DataFrame (action history)\n",
    "    demograph,  # Right DataFrame (demographics)\n",
    "    left_on='send_timestamp',  # Key column in the left DataFrame\n",
    "    right_on='batch_date',  # Key column in the right DataFrame\n",
    "    left_by='customer_code',  # Group by 'customer_code' in the left DataFrame\n",
    "    right_by='CUSTOMER_CODE',  # Group by 'CUSTOMER_CODE' in the right DataFrame\n",
    "    direction='backward'  # Match the closest previous row in the right DataFrame\n",
    ")\n",
    "\n",
    "# Ensure all customer codes from the demographics DataFrame appear in the merged DataFrame\n",
    "# Perform a left join with the demographics DataFrame to include all customer codes\n",
    "all_customers_df = demograph[['CUSTOMER_CODE']].drop_duplicates().rename(columns={'CUSTOMER_CODE': 'customer_code'})\n",
    "merged_df = pd.merge(all_customers_df, merged_df, on='customer_code', how='left')\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(\"Merged DataFrame:\\n\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the 'send_timestamp_slot' column\n",
    "merged_df = pd.get_dummies(merged_df, columns=['send_timestamp_slot'], prefix_sep='_', dtype=int)\n",
    "merged_df.drop(columns=['open_timestamp', 'open_timestamp_slot', 'CUSTOMER_CODE', 'batch_date', 'Unnamed: 0'], inplace=True)\n",
    "merged_df.drop(columns=['send_timestamp'], inplace=True)\n",
    "merged_df = merged_df.groupby('customer_code').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_customers = pd.read_csv('test_customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdna = pd.read_csv('test_cdna_data.csv')\n",
    "test_action_history = pd.read_csv('test_action_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_values = set(merged_df['customer_code']).intersection(set(test_customers['CUSTOMER_CODE']))\n",
    "print(f\"common: {len(common_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for numeric columns only\n",
    "numeric_columns = merged_df.select_dtypes(include=['number']).columns\n",
    "merged_df[numeric_columns] = merged_df[numeric_columns].fillna(merged_df[numeric_columns].mean())\n",
    "\n",
    "# Fill missing values for non-numeric columns (e.g., datetime, categorical)\n",
    "non_numeric_columns = merged_df.select_dtypes(exclude=['number']).columns\n",
    "merged_df[non_numeric_columns] = merged_df[non_numeric_columns].fillna('NA')  # Use 'NA' or any placeholder\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(\"Merged DataFrame after filling missing values:\\n\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove rows from merged_df where customer_code is not in test_customers\n",
    "merged_df = merged_df[merged_df['customer_code'].isin(test_customers['CUSTOMER_CODE'])]\n",
    "\n",
    "# Step 2: Reorder merged_df according to the order of CUSTOMER_CODES in test_customers\n",
    "# Create a mapping of CUSTOMER_CODE to their order in test_customers\n",
    "order_mapping = {code: idx for idx, code in enumerate(test_customers['CUSTOMER_CODE'])}\n",
    "merged_df['order'] = merged_df['customer_code'].map(order_mapping)\n",
    "\n",
    "# Sort merged_df based on the order\n",
    "merged_df = merged_df.sort_values(by='order').drop(columns=['order'])\n",
    "\n",
    "# Step 3: Add missing customer_codes from test_customers and fill with NA and column means\n",
    "# Create a DataFrame with all CUSTOMER_CODES from test_customers\n",
    "aligned_df = pd.DataFrame({'customer_code': test_customers['CUSTOMER_CODE']})\n",
    "\n",
    "# Merge with merged_df to align rows according to test_customers\n",
    "aligned_df = aligned_df.merge(merged_df, on='customer_code', how='left')\n",
    "\n",
    "# Fill missing numeric columns with their mean\n",
    "numeric_columns = merged_df.select_dtypes(include=['number']).columns\n",
    "mean_values = merged_df[numeric_columns].mean()\n",
    "aligned_df[numeric_columns] = aligned_df[numeric_columns].fillna(mean_values)\n",
    "\n",
    "# Fill missing non-numeric columns with a placeholder (e.g., 'NA')\n",
    "non_numeric_columns = merged_df.select_dtypes(exclude=['number']).columns\n",
    "aligned_df[non_numeric_columns] = aligned_df[non_numeric_columns].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_df.drop(columns=['customer_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading Base and Meta model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = joblib.load('meta_model.pkl')\n",
    "base_models = joblib.load('base_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time_slots(base_model, meta_model, input_data):\n",
    "    \"\"\"\n",
    "    Predicts the ranked time slots for a single input row using a stacking model.\n",
    "\n",
    "    Parameters:\n",
    "    base_model (sklearn model): Trained base regression model.\n",
    "    meta_model (sklearn model): Trained meta regression model.\n",
    "    input_data (array-like): Single row of input data (features).\n",
    "\n",
    "    Returns:\n",
    "    dict: Predicted probabilities and ranked slots.\n",
    "    \"\"\"\n",
    "    # Ensure input_data is a 2D array for prediction\n",
    "    input_array = np.array(input_data).reshape(1, -1)\n",
    "\n",
    "    # Step 1: Get base model prediction for the input row\n",
    "    base_prediction = base_model.predict(input_array).reshape(1, -1)\n",
    "\n",
    "    # Step 2: Combine original input with base prediction for meta-model\n",
    "    stacked_input = np.hstack((input_array, base_prediction))\n",
    "\n",
    "    # Step 3: Predict probabilities using the meta-model\n",
    "    predicted_probs = meta_model.predict(stacked_input).reshape(1, -1)\n",
    "\n",
    "    # Step 4: Rank slots by predicted probabilities\n",
    "    slot_names = [f\"slot_{i+1}\" for i in range(predicted_probs.shape[1])]\n",
    "    sorted_slots = sorted(zip(slot_names, predicted_probs[0]), key=lambda x: -x[1])\n",
    "\n",
    "    # Extract ranked slots and probabilities\n",
    "    ranked_slots = [slot for slot, _ in sorted_slots]\n",
    "    ranked_probs = [prob for _, prob in sorted_slots]\n",
    "\n",
    "    return {\n",
    "        \"ranked_slots\": ranked_slots,\n",
    "        \"ranked_probs\": ranked_probs\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Predictions on Test Data and Saving Results\n",
    "This cell performs the following steps:\n",
    "\n",
    "1) Initialize Predictions List: A list (predictions) is initialized to store the prediction results for each customer.\n",
    "\n",
    "2) Load Preprocessed Test Data: The preprocessed test data (test_data_finally_preprocessed.csv) is loaded into the merged_df DataFrame.\n",
    "\n",
    "3) Iterate Through Each Row: For each row in the DataFrame, the input data is prepared, and predictions are made using the predict_time_slots function.\n",
    "\n",
    "4) Store Predictions: The predictions are stored in the predictions list.\n",
    "\n",
    "5) Save Predictions to CSV: The predictions are converted to a DataFrame and saved to a CSV file (predicted_slots.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "merged_df = pd.read_csv('test_data_finally_preprocessed.csv')\n",
    "# Iterate through each row in merged_df\n",
    "for index, row in merged_df.iterrows():\n",
    "    # Extract input data (excluding the customer_code column if present)\n",
    "    input_data = row.drop('customer_code').values if 'customer_code' in merged_df.columns else row.values\n",
    "\n",
    "    # Predict ranked slots for the current row\n",
    "    result = predict_time_slots(base_models, meta_model, input_data)\n",
    "\n",
    "    # Append the result to the predictions list\n",
    "    predictions.append({\n",
    "        'customer_code': row['customer_code'] if 'customer_code' in merged_df.columns else index,\n",
    "        'predicted_slots_order': result['ranked_slots']\n",
    "    })\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_df.to_csv('predicted_slots.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predicted_slots.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slots csv preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['predicted_slots_order'] = predictions_df['predicted_slots_order'].str.replace(\"'\", \"\")\n",
    "test_customers = pd.read_csv('test_customers.csv')\n",
    "customer_codes = test_customers['CUSTOMER_CODE']\n",
    "predictions_df['customer_code'] = customer_codes\n",
    "predictions_df.to_csv('predicted_slots_final_v3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
